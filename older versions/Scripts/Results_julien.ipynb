{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import folium\n",
    "import pickle\n",
    "import numpy as np\n",
    "from ipywidgets import interact\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file=\"./Data/uni_df.pkl\"\n",
    "df=pickle.load(open(pickle_file,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final features ['Sweet potatoes Crops Production tonnes', 'Soybeans Crops Production tonnes', 'Tomatoes Crops Production tonnes', 'Oats Crops Production tonnes', 'Buffaloes Livestock production Head', 'Cassava Crops Production tonnes', 'Barley Crops Production tonnes', 'Rabbits and hares Livestock production Head', 'Maize Crops Production tonnes', 'Goats Livestock production Head', 'Turkeys Livestock production Head', 'Ducks Livestock production Head', 'Sugar beet Crops Production tonnes', 'Potatoes Crops Production tonnes', 'Wheat Crops Production tonnes', 'Pigs Livestock production Head', 'Cattle Livestock production Head', 'Sheep Livestock production Head', 'Sheep and Goats Livestock production Head', 'Chickens Livestock production Head', 'Barley Food export quantities tonnes', 'Buffaloes Live animals export quantities Head', 'Cassava Food export quantities tonnes', 'Cattle Live animals export quantities Head', 'Chickens Live animals export quantities Head', 'Ducks Live animals export quantities Head', 'Goats Live animals export quantities Head', 'Maize Food export quantities tonnes', 'Maize, green Food export quantities tonnes', 'Oats Food export quantities tonnes', 'Pigs Live animals export quantities Head', 'Potatoes Food export quantities tonnes', 'Rabbits and hares Live animals export quantities Head', 'Sheep Live animals export quantities Head', 'Sheep and Goats Live animals export quantities Head', 'Sheep and Goats Live animals export quantities Head', 'Sheep and Goats Live animals export quantities Head', 'Soybeans Food export quantities tonnes', 'Sugar beet Food export quantities tonnes', 'Sweet potatoes Food export quantities tonnes', 'Tomatoes Food export quantities tonnes', 'Turkeys Live animals export quantities Head', 'Wheat Food export quantities tonnes', 'Barley Food import quantities tonnes', 'Buffaloes Live animals import quantities Head', 'Cassava Food import quantities tonnes', 'Cattle Live animals import quantities Head', 'Chickens Live animals import quantities Head', 'Ducks Live animals import quantities Head', 'Goats Live animals import quantities Head', 'Maize Food import quantities tonnes', 'Maize, green Food import quantities tonnes', 'Oats Food import quantities tonnes', 'Pigs Live animals import quantities Head', 'Potatoes Food import quantities tonnes', 'Rabbits and hares Live animals import quantities Head', 'Sheep Live animals import quantities Head', 'Sheep and Goats Live animals import quantities Head', 'Sheep and Goats Live animals import quantities Head', 'Sheep and Goats Live animals import quantities Head', 'Soybeans Food import quantities tonnes', 'Sugar beet Food import quantities tonnes', 'Sweet potatoes Food import quantities tonnes', 'Tomatoes Food import quantities tonnes', 'Turkeys Live animals import quantities Head', 'Wheat Food import quantities tonnes']\n",
      "list of all features ['Sweet potatoes Crops Production tonnes', 'Soybeans Crops Production tonnes', 'Tomatoes Crops Production tonnes', 'Oats Crops Production tonnes', 'Buffaloes Livestock production Head', 'Cassava Crops Production tonnes', 'Barley Crops Production tonnes', 'Rabbits and hares Livestock production Head', 'Maize Crops Production tonnes', 'Goats Livestock production Head', 'Turkeys Livestock production Head', 'Ducks Livestock production Head', 'Sugar beet Crops Production tonnes', 'Potatoes Crops Production tonnes', 'Wheat Crops Production tonnes', 'Pigs Livestock production Head', 'Cattle Livestock production Head', 'Sheep Livestock production Head', 'Sheep and Goats Livestock production Head', 'Chickens Livestock production Head', 'Barley Food export quantities tonnes', 'Buffaloes Live animals export quantities Head', 'Cassava Food export quantities tonnes', 'Cattle Live animals export quantities Head', 'Chickens Live animals export quantities Head', 'Ducks Live animals export quantities Head', 'Goats Live animals export quantities Head', 'Maize Food export quantities tonnes', 'Maize, green Food export quantities tonnes', 'Oats Food export quantities tonnes', 'Pigs Live animals export quantities Head', 'Potatoes Food export quantities tonnes', 'Rabbits and hares Live animals export quantities Head', 'Sheep Live animals export quantities Head', 'Sheep and Goats Live animals export quantities Head', 'Sheep and Goats Live animals export quantities Head', 'Sheep and Goats Live animals export quantities Head', 'Soybeans Food export quantities tonnes', 'Sugar beet Food export quantities tonnes', 'Sweet potatoes Food export quantities tonnes', 'Tomatoes Food export quantities tonnes', 'Turkeys Live animals export quantities Head', 'Wheat Food export quantities tonnes', 'Barley Food import quantities tonnes', 'Buffaloes Live animals import quantities Head', 'Cassava Food import quantities tonnes', 'Cattle Live animals import quantities Head', 'Chickens Live animals import quantities Head', 'Ducks Live animals import quantities Head', 'Goats Live animals import quantities Head', 'Maize Food import quantities tonnes', 'Maize, green Food import quantities tonnes', 'Oats Food import quantities tonnes', 'Pigs Live animals import quantities Head', 'Potatoes Food import quantities tonnes', 'Rabbits and hares Live animals import quantities Head', 'Sheep Live animals import quantities Head', 'Sheep and Goats Live animals import quantities Head', 'Sheep and Goats Live animals import quantities Head', 'Sheep and Goats Live animals import quantities Head', 'Soybeans Food import quantities tonnes', 'Sugar beet Food import quantities tonnes', 'Sweet potatoes Food import quantities tonnes', 'Tomatoes Food import quantities tonnes', 'Turkeys Live animals import quantities Head', 'Wheat Food import quantities tonnes']\n",
      "amount of selected features 15\n",
      "selected features ['Soybeans Crops Production tonnes', 'Tomatoes Crops Production tonnes', 'Maize Crops Production tonnes', 'Turkeys Livestock production Head', 'Chickens Livestock production Head', 'Maize Food export quantities tonnes', 'Maize, green Food export quantities tonnes', 'Soybeans Food export quantities tonnes', 'Wheat Food export quantities tonnes', 'Cattle Live animals import quantities Head', 'Oats Food import quantities tonnes', 'Pigs Live animals import quantities Head', 'Tomatoes Food import quantities tonnes', 'Turkeys Live animals import quantities Head', 'GDP']\n",
      "list of selected features after reduction ['Soybeans Crops Production tonnes', 'Tomatoes Crops Production tonnes', 'Maize Crops Production tonnes', 'Turkeys Livestock production Head', 'Maize Food export quantities tonnes', 'Maize, green Food export quantities tonnes', 'Wheat Food export quantities tonnes', 'Cattle Live animals import quantities Head', 'Oats Food import quantities tonnes', 'Pigs Live animals import quantities Head', 'Tomatoes Food import quantities tonnes', 'Turkeys Live animals import quantities Head']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22574769179207.75, tolerance: 641076863381.032\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best regularization parameter is  0.01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_target_and_covariate_df(path_to_pkl):\n",
    "    '''\n",
    "    path_to_pkl: path to the pickle file.\n",
    "    outputs two dataframes, one for the independant variables one for the dependant variables\n",
    "    '''\n",
    "    \n",
    "    uni_df = pd.read_pickle(path_to_pkl)\n",
    "    uni_df = uni_df.drop(columns=['Area', 'Year'])\n",
    "    target_variables_df = uni_df[['(GDP, million $)', '(Consumer price indices, %)']]\n",
    "    covariates_df = uni_df.drop(columns=['(GDP, million $)', '(Consumer price indices, %)'])\n",
    "    \n",
    "    return covariates_df, target_variables_df\n",
    "\n",
    "\n",
    "def drop_feature_pearson_correlation(threshold, target_variable, target_variable_name, dataframe):\n",
    "    \n",
    "    '''\n",
    "    threshold: the minimum amount of correlation required to keep the feature\n",
    "    target_variable_name: string GDP or CPI\n",
    "    normalised_dataset: the normalised dataset of feature\n",
    "    target_variable: pandas series that contains the value of the target_varibale_name\n",
    "    that we add to the normalised dataset\n",
    "    \n",
    "    '''\n",
    "    copy_dataframe = dataframe.copy()\n",
    "    copy_dataframe[target_variable_name] = target_variable\n",
    "    cor = copy_dataframe.corr()\n",
    "    cor_target = abs(cor[target_variable_name])\n",
    "    \n",
    "    relevant_features = cor_target[cor_target > threshold]\n",
    "    \n",
    "    return list(relevant_features.keys())\n",
    "\n",
    "def drop_too_corelated_featues(threshold, dataframe):\n",
    "    \n",
    "    corr_matrix = dataframe.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    \n",
    "    return dataframe.drop(dataframe[to_drop], axis=1)\n",
    "    \n",
    "\n",
    "def feature_augmentation(degree, covariates_df):\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    output_nparray =  poly.fit_transform(covariates_df)\n",
    "\n",
    "    \n",
    "    output_df = pd.DataFrame(output_nparray, columns = poly.get_feature_names(covariates_df.columns))\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "def split_and_standardization_dataset(target_variables, covariates, test_size, random, type_return = 'numpy'  ):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    target_variables: pandas dataframe that contains the target variables\n",
    "    covariates: pandas dataframe that contains the independant variables\n",
    "    test_size: the proportion of the dataset to include in the test split\n",
    "    type_return: 'numpy' if return numpy array, 'pandas' if return pandas dataframe\n",
    "    '''\n",
    "    target_variables_numpy = target_variables.to_numpy()\n",
    "    covariates_numpy = covariates.to_numpy()\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(covariates_numpy, target_variables_numpy, test_size=test_size, random_state = random)\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train_normalized = scaler.transform(X_train)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "    \n",
    "    if type_return == 'numpy':\n",
    "        \n",
    "        return X_train_normalized, X_test_normalized, Y_train, Y_test\n",
    "    \n",
    "    elif type_return == 'pandas':\n",
    "        \n",
    "        X_test_normalized_df = pd.DataFrame(X_test_normalized, columns = list(covariates.columns))\n",
    "        X_train_normalized_df = pd.DataFrame(X_train_normalized,columns= list(covariates.columns))\n",
    "        Y_train_df = pd.DataFrame(Y_train, columns= list(target_variables.columns))\n",
    "        Y_test_df = pd.DataFrame(Y_test, columns= list(target_variables.columns))\n",
    "        \n",
    "        return X_train_normalized_df, X_test_normalized_df, Y_train_df, Y_test_df\n",
    "\n",
    "def fit_model_lasso(regularisation_parameters, covariates_df, target_df, nb_fold_CV):\n",
    "    \n",
    "    lasso = Lasso()\n",
    "    \n",
    "    parameters = {'alpha': regularisation_parameters}\n",
    "    \n",
    "    lasso_regressor = GridSearchCV(lasso, parameters, scoring = 'neg_mean_squared_error', cv = nb_fold_CV)\n",
    "    lasso_regressor.fit(covariates_df, target_df)\n",
    "\n",
    "    best_param = lasso_regressor.best_params_['alpha']\n",
    "    print('The best regularization parameter is ', best_param)\n",
    "\n",
    "\n",
    "    lasso = Lasso(alpha=best_param)\n",
    "    lasso.fit(covariates_df, target_df)\n",
    "    return lasso.coef_\n",
    "    \n",
    "    \n",
    "    \n",
    "def RFECV_lasso_2(covariate, target,  random, nb_fold = 5,):\n",
    "    \n",
    "    cols = list(covariate.columns)\n",
    "    X_train_, X_test_, Y_train_, Y_test_ = split_and_standardization_dataset(target, covariate, 0.2, type_return='numpy', random = random)\n",
    "    #print('shape of Y_train_', Y_train_.shape, 'type of Y_train_', type(Y_train_))\n",
    "    model = Lasso()\n",
    "    \n",
    "    rfecv = RFECV(estimator = model, step = 1, cv = nb_fold, scoring = 'neg_mean_squared_error')\n",
    "    rfecv.fit(X_train_, np.ravel(Y_train_))\n",
    "    print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "    \n",
    "    temp = pd.Series(rfecv.support_,index = cols)\n",
    "    selected_features = temp[temp==True].index\n",
    "\n",
    "    print(selected_features)\n",
    "    \n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.xlabel(\"Number of features selected\")\n",
    "    # plt.ylabel(\"Cross validation score\")\n",
    "    # plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "    # plt.show()\n",
    "        \n",
    "    return selected_features\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def main():\n",
    "\n",
    "    RANDOM_SEED = 29\n",
    "\n",
    "    params = {\n",
    "\n",
    "        'target' : '(GDP, million $)',\n",
    "        'name of target': 'GDP',\n",
    "        'pearson correlation threshold': 0.4,\n",
    "        'inter correlation threshold': 0.9, \n",
    "        'nb_fold_CV': 5, \n",
    "        'degree augmentation': 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "    covariates_df, target_variables_df = create_target_and_covariate_df('./Data/uni_df.pkl')\n",
    "    target_variables_df.to_pickle('target.pkl')\n",
    "\n",
    "    ### Below we are going to select the top 20 features in production:\n",
    "\n",
    "    Production_cov_df = covariates_df.filter(regex= 'production|Production')\n",
    "    summed_df = Production_cov_df.sum()\n",
    "    keys = summed_df.keys()\n",
    "    values = summed_df.values\n",
    "    sorted_keys = [key for _,key in sorted(zip(values,keys))]\n",
    "    Production_cov_df = Production_cov_df[sorted_keys[-20:]]\n",
    "    selected_features_production = list(Production_cov_df.columns.values) # Selected features for top 20 prod features in volumne\n",
    "\n",
    "    cropped_word_selected_prod = [\" \".join(string.split()[:-3]) for string in selected_features_production] # Same as the list above with only the important words kept\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "   #-------------------------Below we are selecting the features in export that have been selected previously with the production--------------------------------------\n",
    "    export_df = covariates_df.filter(regex= 'export')\n",
    "    \n",
    "\n",
    "    columns_to_keep_export = []\n",
    "\n",
    "    for column_export in list(export_df.columns.values):\n",
    "\n",
    "        for columns_prod in cropped_word_selected_prod:\n",
    "\n",
    "            if columns_prod in column_export:\n",
    "\n",
    "                columns_to_keep_export.append(column_export)\n",
    "\n",
    "\n",
    "    #-------------------------Below we are selecting the features in import that have been selected previously with the production--------------------------------------\n",
    "    import_df = covariates_df.filter(regex= 'import')\n",
    "    \n",
    "\n",
    "    columns_to_keep_import = []\n",
    "\n",
    "    for column_import in list(import_df.columns.values):\n",
    "\n",
    "        for columns_prod in cropped_word_selected_prod:\n",
    "\n",
    "            if columns_prod in column_import:\n",
    "\n",
    "                columns_to_keep_import.append(column_import)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    final_features_kept = selected_features_production + columns_to_keep_export + columns_to_keep_import  # All the selected features\n",
    "    print('final features', final_features_kept)\n",
    "\n",
    "    # summed_covariates_df = covariates_df.sum()\n",
    "    # keys = summed_covariates_df.keys()\n",
    "    # values = summed_covariates_df.values\n",
    "    \n",
    "    # sorted_keys = [key for _,key in sorted(zip(values,keys))]\n",
    "\n",
    "    # covariates_df = covariates_df[sorted_keys[-30:]]\n",
    "    covariates_df = covariates_df[final_features_kept]\n",
    "    \n",
    "    # covariates_df = feature_augmentation(2, covariates_df)\n",
    "    print('list of all features', list(covariates_df.columns.values))\n",
    "    list_selected_features_GDP = drop_feature_pearson_correlation(params['pearson correlation threshold'], target_variables_df[params['target']], params['name of target'], covariates_df)\n",
    "    print('amount of selected features', len(list_selected_features_GDP))\n",
    "    print('selected features', list_selected_features_GDP)\n",
    "    covariate_reduced_df = covariates_df[list_selected_features_GDP[:-1]]\n",
    "\n",
    "    covariate_reduced_df = drop_too_corelated_featues(params['inter correlation threshold'], covariate_reduced_df)\n",
    "    covariate_reduced_df.to_pickle(\"reduced_df_2.pkl\")\n",
    "    print('list of selected features after reduction', list(covariate_reduced_df.columns.values))\n",
    "    # covariate_reduced_df = feature_augmentation(params['degree augmentation'], covariate_reduced_df)\n",
    "\n",
    "    # selected_features = RFECV_lasso_2(covariate_reduced_df, target_variables_df[[params['target']]], random = RANDOM_SEED)\n",
    "    # selected_covariate = covariate_reduced_df[selected_features]\n",
    "\n",
    "    regularisation_parameters = np.linspace(start = 0.01, stop= 1, num = 20)\n",
    "\n",
    "    # covariate_reduced_df = covariate_reduced_df[list(selected_covariate.columns.values)]\n",
    "\n",
    "    target_df = target_variables_df[params['target']]\n",
    "\n",
    "    nb_fold_CV = params['nb_fold_CV']\n",
    "\n",
    "    param_lasso = fit_model_lasso(regularisation_parameters, covariate_reduced_df, target_df, nb_fold_CV = nb_fold_CV )\n",
    "\n",
    "    keys = list(covariate_reduced_df.columns.values)\n",
    "    #keys = selected_features\n",
    "    values = param_lasso\n",
    "   \n",
    "    return dict(zip(keys, values))\n",
    "\n",
    "weights=main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "\n",
    "def visualise_world_data_folium(df, to_visualise, year, log=True,log2=False):\n",
    "    \n",
    "    if log2:\n",
    "        log=False\n",
    "    if log:\n",
    "        log2=False\n",
    "        \n",
    "    # Defining color palette\n",
    "    color_scale = sns.cubehelix_palette(9)\n",
    "    \n",
    "    # importing geojson and transforming to pandas\n",
    "    geo_data=json.load(open(\"./Data/world-countries.json\"))\n",
    "    dics=geo_data['features']\n",
    "    clean_dics=[]\n",
    "    for country in dics:\n",
    "        clean_dics.append({'Country':country['properties']['name'],\n",
    "                          'geometry':country['geometry']})\n",
    "    geo_df=pd.DataFrame(clean_dics)\n",
    "    \n",
    "    # cropping to df to data of interest\n",
    "    df_visu=df[df.Year==year][['Area',to_visualise]]\n",
    "\n",
    "    # Merging with geo data\n",
    "    df_visu=geo_df.merge(df_visu,how='left',left_on='Country',right_on='Area')\n",
    "    df_visu=df_visu.dropna()\n",
    "    \n",
    "    if log:\n",
    "        df_visu['to_plot']=df_visu[to_visualise].apply(lambda x : np.log10(x))\n",
    "        \n",
    "    def log2_scale(x):\n",
    "        out=np.sign(x)*np.log10(1+np.abs(x))\n",
    "        return out\n",
    "        \n",
    "    if log2:\n",
    "        df_visu['to_plot']=df_visu[to_visualise].apply(log2_scale)\n",
    "    \n",
    "    # creating bins for color scaling\n",
    "    ma_value=df_visu['to_plot'].max()\n",
    "    mi_value=df_visu['to_plot'].min()\n",
    "    bins=np.linspace(mi_value,ma_value,8)\n",
    "    \n",
    "    # creating Json string for folium\n",
    "    features=[]\n",
    "    for _,row in df_visu.iterrows():\n",
    "        color=np.digitize(row['to_plot'],bins)\n",
    "        val=row[to_visualise]\n",
    "        feature={\n",
    "            'type' : 'Feature',\n",
    "            \n",
    "            'properties':{'name':row['Country'],\n",
    "                          'value': '{:.2E}'.format(val),\n",
    "                          'color':colors.to_hex(color_scale[color])},\n",
    "            'geometry':row['geometry']\n",
    "            }\n",
    "        features.append(feature)\n",
    "    \n",
    "    def style(feature):\n",
    "        \n",
    "        if feature['properties']['value']==np.nan:\n",
    "            print(\"lol\")\n",
    "            opac=0\n",
    "        else:\n",
    "            opac=0.8\n",
    "        return {'fillOpacity':opac,\n",
    "                   'weight':0.1,\n",
    "                   'fillColor':feature['properties']['color']}\n",
    "    geo_data=folium.GeoJson({'type':'FeatureCollection','features':features},\n",
    "                            style_function=style,\n",
    "                            tooltip=folium.features.GeoJsonTooltip(['name','value']))\n",
    "    m=folium.Map()\n",
    "    geo_data.add_to(m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Soybeans Crops Production tonnes': 0.01690455171988309,\n",
       " 'Tomatoes Crops Production tonnes': 0.04600299893471081,\n",
       " 'Maize Crops Production tonnes': 0.019112555979080622,\n",
       " 'Turkeys Livestock production Head': 0.00045609049200983894,\n",
       " 'Maize Food export quantities tonnes': -0.06316454222878924,\n",
       " 'Maize, green Food export quantities tonnes': 52.08283849392848,\n",
       " 'Wheat Food export quantities tonnes': 0.007579959466075064,\n",
       " 'Cattle Live animals import quantities Head': 0.03663454785851843,\n",
       " 'Oats Food import quantities tonnes': 0.4837657071630528,\n",
       " 'Pigs Live animals import quantities Head': 0.05776106945901834,\n",
       " 'Tomatoes Food import quantities tonnes': 2.568655777314169,\n",
       " 'Turkeys Live animals import quantities Head': 0.04929538371588097}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=list(weights.keys())\n",
    "df=pickle.load(open(pickle_file,'rb'))\n",
    "df=df.set_index(['Area','Year'])\n",
    "prod_to_plot=pd.DataFrame(index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soybeans Crops Production tonnes\n",
      "Tomatoes Crops Production tonnes\n",
      "Maize Crops Production tonnes\n",
      "Turkeys Livestock production Head\n",
      "Maize Food export quantities tonnes\n",
      "Maize, green Food export quantities tonnes\n",
      "Wheat Food export quantities tonnes\n",
      "Cattle Live animals import quantities Head\n",
      "Oats Food import quantities tonnes\n",
      "Pigs Live animals import quantities Head\n",
      "Tomatoes Food import quantities tonnes\n",
      "Turkeys Live animals import quantities Head\n"
     ]
    }
   ],
   "source": [
    "columns=list(weights.keys())\n",
    "df=pickle.load(open(pickle_file,'rb'))\n",
    "df=df.set_index(['Area','Year'])\n",
    "prod_to_plot=pd.DataFrame(index=df.index)\n",
    "dic_to_plot={}\n",
    "for c in columns:\n",
    "    print(c)\n",
    "    if 'Production' in c or 'production' in c:\n",
    "        if len(df.filter(regex=c).columns)==0:\n",
    "            print('{} not found'.format(c))\n",
    "        else:\n",
    "            dic_to_plot.update(df.filter(regex=c).to_dict())\n",
    "    else:\n",
    "        s=re.split(' Food| Live',c)[0]\n",
    "        s='^'+s\n",
    "        s=(s+'.*Production.*tonnes$|'\n",
    "           +s+'.*Production.*Head$|'\n",
    "           +s+'.*production.*tonnes$|'\n",
    "           +s+'.*production.*Head')\n",
    "        if len(df.filter(regex=s).columns)==0:\n",
    "            print('{} not found'.format(c))\n",
    "        else:\n",
    "            dic_to_plot.update(df.filter(regex=s).to_dict())\n",
    "prod_to_plot=pd.DataFrame(dic_to_plot)\n",
    "prod_to_plot=prod_to_plot.reset_index().rename(columns={'level_0':'Area','level_1':'Year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Year</th>\n",
       "      <th>Soybeans Crops Production tonnes</th>\n",
       "      <th>Tomatoes Crops Production tonnes</th>\n",
       "      <th>Maize Crops Production tonnes</th>\n",
       "      <th>Turkeys Livestock production Head</th>\n",
       "      <th>Maize, green Crops Production tonnes</th>\n",
       "      <th>Wheat Crops Production tonnes</th>\n",
       "      <th>Cattle Livestock production Head</th>\n",
       "      <th>Oats Crops Production tonnes</th>\n",
       "      <th>Pigs Livestock production Head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>667000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2081000.0</td>\n",
       "      <td>3700000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Area  Year  Soybeans Crops Production tonnes  \\\n",
       "0  Afghanistan  1970                               0.0   \n",
       "\n",
       "   Tomatoes Crops Production tonnes  Maize Crops Production tonnes  \\\n",
       "0                               0.0                       667000.0   \n",
       "\n",
       "   Turkeys Livestock production Head  Maize, green Crops Production tonnes  \\\n",
       "0                                0.0                                   0.0   \n",
       "\n",
       "   Wheat Crops Production tonnes  Cattle Livestock production Head  \\\n",
       "0                      2081000.0                         3700000.0   \n",
       "\n",
       "   Oats Crops Production tonnes  Pigs Livestock production Head  \n",
       "0                           0.0                             0.0  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_to_plot.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c107d5bf88e4547956e0de888fc8b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1992, description='x', max=2015, min=1970), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1cd1b0d0c64a919d29a6ebf82e0656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1992, description='x', max=2015, min=1970), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns=[w for w in prod_to_plot.columns if w!='Area' and w!='Year']\n",
    "for c in columns[:2]:\n",
    "    display(interact(lambda x : visualise_world_data_folium(prod_to_plot,c,x,log2=True),x=(1970,2015,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_to_plot=prod_to_plot.reset_index().rename(columns={'level_0':'Area','level_1':'Year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "#Generate result files\n",
    "\n",
    "#if needed, creating result directory\n",
    "if not os.path.exists('./Data/ResultsJulien'):\n",
    "    os.mkdir('./Data/ResultsJulien')\n",
    "if not os.path.exists('./Data/ResultsJulien/Producers'):\n",
    "        os.mkdir('./Data/ResultsJulien/Producers')\n",
    "        \n",
    "for c in prod_to_plot.columns:\n",
    "    if c!='Year' and c!='Area':\n",
    "        \n",
    "        #if the dir already exists, remove it and create fresh one\n",
    "        if os.path.exists('./Data/ResultsJulien/Producers/{}'.format(c)):\n",
    "            shutil.rmtree('./Data/ResultsJulien/Producers/{}'.format(c))\n",
    "        #wait for the deletion to be complete\n",
    "        while os.path.exists('./Data/ResultsJulien/Producers/{}'.format(c)):\n",
    "            continue\n",
    "        os.mkdir('./Data/ResultsJulien/Producers/{}'.format(c))\n",
    "        \n",
    "        for year in range(1970,2015,1):\n",
    "            m=visualise_world_data_folium(prod_to_plot,c,year,log2=True)\n",
    "            save_name='./Data/ResultsJulien/Producers/{}/{}_{}.html'.format(c,c,year)\n",
    "            m.save(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_self_suficiency(df,w=None):\n",
    "    \n",
    "    # From the unified dataframe df, compute the self sufficiency score for each year for each country\n",
    "    # if a paramter of weights is given as a dict, the method returns the aggregated score.\n",
    "    \n",
    "    weights=w.copy()\n",
    "    \n",
    "    #Useful method to manipulate names\n",
    "    def drop_words( s , w=1 , end=True):\n",
    "        if end:\n",
    "            return s.rsplit(' ',w)[0]\n",
    "        else:\n",
    "            return s.split(' ',w)[-1]\n",
    "    \n",
    "    df=df.set_index(['Area','Year'])\n",
    "    \n",
    "    #Getting the columns corresponding to import, export and production\n",
    "    import_cols=[col for col in df.columns if 'import' in col.lower()]\n",
    "    export_cols=[col for col in df.columns if 'export' in col.lower()]\n",
    "    prod_cols=[col for col in df.columns if 'production' in col.lower()]\n",
    "    \n",
    "    #Initializing new dataframe\n",
    "    scores=pd.DataFrame(index=df.index)\n",
    "    \n",
    "    #Generating scores\n",
    "    for i,col in enumerate(import_cols):\n",
    "        scores[drop_words(col,3)]=(df[prod_cols[i]]*100/(\n",
    "                                    df[prod_cols[i]]+df[import_cols[i]]-df[export_cols[i]]))\n",
    "    \n",
    "    #If no weights, return scores without aggregate\n",
    "    if weights==None:\n",
    "        return scores\n",
    "    \n",
    "    features=[w for w in weights.keys()]\n",
    "    temp=pd.DataFrame(index=df.index)\n",
    "    \n",
    "    #replacing na with 0 to avoid na aggregated scores\n",
    "    scores=scores.fillna(0)\n",
    "    \n",
    "    #Selecting features of interest\n",
    "    temp_dic={}\n",
    "    popped=[]\n",
    "    for feat in list(weights.keys()):\n",
    "        if feat not in popped:\n",
    "            w_agg={feat:weights[feat]}\n",
    "            s=re.split(' Food| Live.*| Crops',feat)[0]\n",
    "            s='^'+s\n",
    "            w=weights[feat]\n",
    "\n",
    "            for f in list(weights.keys()):\n",
    "                if f!=feat and re.search(s,f) and s[1:]==re.split(' Food.*| Live.*| Crops.*',f)[0]:\n",
    "                    w+=weights[f]\n",
    "                    w_agg.update({f:weights[f]})\n",
    "                    popped.append(f)\n",
    "                    \n",
    "\n",
    "            if len(scores.filter(regex=s).columns)==0:\n",
    "                print('\\n {} NOT FOUND'.format(feat))\n",
    "            else:\n",
    "                print('{} weight : {} agg from: {}'.format(feat,w,w_agg))\n",
    "                temp_df=scores.filter(regex=s).copy()\n",
    "                temp_df=temp_df.apply(lambda x: x*w)\n",
    "                temp_dic.update(temp_df.to_dict())\n",
    "            \n",
    "    temp=pd.DataFrame(temp_dic)\n",
    "    #Aggregating the scores\n",
    "    scores=pd.DataFrame(temp.sum(axis=1),columns=['Agg'])\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pickle.load(open(pickle_file,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soybeans Crops Production tonnes weight : 0.01690455171988309 agg from: {'Soybeans Crops Production tonnes': 0.01690455171988309}\n",
      "Tomatoes Crops Production tonnes weight : 2.6146587762488798 agg from: {'Tomatoes Crops Production tonnes': 0.04600299893471081, 'Tomatoes Food import quantities tonnes': 2.568655777314169}\n",
      "Maize Crops Production tonnes weight : -0.044051986249708616 agg from: {'Maize Crops Production tonnes': 0.019112555979080622, 'Maize Food export quantities tonnes': -0.06316454222878924}\n",
      "Turkeys Livestock production Head weight : 0.04975147420789081 agg from: {'Turkeys Livestock production Head': 0.00045609049200983894, 'Turkeys Live animals import quantities Head': 0.04929538371588097}\n",
      "Maize, green Food export quantities tonnes weight : 52.08283849392848 agg from: {'Maize, green Food export quantities tonnes': 52.08283849392848}\n",
      "Wheat Food export quantities tonnes weight : 0.007579959466075064 agg from: {'Wheat Food export quantities tonnes': 0.007579959466075064}\n",
      "Cattle Live animals import quantities Head weight : 0.03663454785851843 agg from: {'Cattle Live animals import quantities Head': 0.03663454785851843}\n",
      "Oats Food import quantities tonnes weight : 0.4837657071630528 agg from: {'Oats Food import quantities tonnes': 0.4837657071630528}\n",
      "Pigs Live animals import quantities Head weight : 0.05776106945901834 agg from: {'Pigs Live animals import quantities Head': 0.05776106945901834}\n"
     ]
    }
   ],
   "source": [
    "sc=compute_self_suficiency(df,weights)\n",
    "sc.reset_index(inplace=True)\n",
    "sc=sc.rename(columns={'level_0':'Area','level_1':'Year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Soybeans Crops Production tonnes': 0.01690455171988309,\n",
       " 'Tomatoes Crops Production tonnes': 0.04600299893471081,\n",
       " 'Maize Crops Production tonnes': 0.019112555979080622,\n",
       " 'Turkeys Livestock production Head': 0.00045609049200983894,\n",
       " 'Maize Food export quantities tonnes': -0.06316454222878924,\n",
       " 'Maize, green Food export quantities tonnes': 52.08283849392848,\n",
       " 'Wheat Food export quantities tonnes': 0.007579959466075064,\n",
       " 'Cattle Live animals import quantities Head': 0.03663454785851843,\n",
       " 'Oats Food import quantities tonnes': 0.4837657071630528,\n",
       " 'Pigs Live animals import quantities Head': 0.05776106945901834,\n",
       " 'Tomatoes Food import quantities tonnes': 2.568655777314169,\n",
       " 'Turkeys Live animals import quantities Head': 0.04929538371588097}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "#Generate result files\n",
    "\n",
    "#if needed, create result directories\n",
    "if not os.path.exists('./Data/ResultsJulien'):\n",
    "    os.mkdir('./Data/ResultsJulien')\n",
    "    \n",
    "#if directory already exists delete it\n",
    "if os.path.exists('./Data/ResultsJulien/SelfSufficiency'):\n",
    "    shutil.rmtree('./Data/ResultsJulien/SelfSufficiency')\n",
    "\n",
    "#While loop necessary to wait until the tree is deleted\n",
    "while os.path.exists('./Data/ResultsJulien/SelfSufficiency'):\n",
    "    continue\n",
    "    \n",
    "os.mkdir('Data/ResultsJulien/SelfSufficiency')\n",
    "    \n",
    "\n",
    "for year in range(1970,2016,1):\n",
    "            m=visualise_world_data_folium(sc,'Agg',year,log2=True)\n",
    "            save_name='./Data/ResultsJulien/SelfSufficiency/self_suf_{}.html'.format(year)\n",
    "            m.save(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\Documents\\\\WORK\\\\EPFL\\\\Master\\\\2019-2020\\\\adaproject\\\\ADA-project\\\\Scripts'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
